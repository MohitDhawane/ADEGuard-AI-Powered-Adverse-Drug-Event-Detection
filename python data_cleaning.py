import pandas as pd

def clean_vaers_data(input_filepath, output_filepath):
    """
    Performs basic pre-cleaning on the consolidated VAERS dataset.

    This includes handling missing values, standardizing categorical data,
    and selecting a relevant subset of columns for the main NLP pipeline.

    Args:
        input_filepath (str): Path to the consolidated CSV file (e.g., 'covid_vaers_master.csv').
        output_filepath (str): Path to save the cleaned CSV file.

    Returns:
        pandas.DataFrame: The cleaned and pre-processed DataFrame.
    """
    print(f"Starting basic pre-cleaning of '{input_filepath}'...")
    
    try:
        df = pd.read_csv(input_filepath, low_memory=False)
    except FileNotFoundError:
        print(f"Error: The input file was not found at '{input_filepath}'.")
        print("Please ensure you have run the data_processing.py script first.")
        return None

    print(f"Initial dataset shape: {df.shape}")
    print("\n--- Initial Missing Value Counts ---")
    print(df[['SYMPTOM_TEXT', 'AGE_YRS', 'SEX', 'VAX_MANU']].isnull().sum())

    # --- 1. Handle Missing SYMPTOM_TEXT (Critical) ---
    # Drop rows where the symptom text is missing, as they are unusable for our NLP tasks.
    df.dropna(subset=['SYMPTOM_TEXT'], inplace=True)
    print(f"\nShape after dropping rows with no SYMPTOM_TEXT: {df.shape}")

    # --- 2. Handle Missing AGE_YRS ---
    # Impute with -1 to represent 'Unknown'. This retains the record for other analyses.
    df['AGE_YRS'].fillna(-1, inplace=True)

    # --- 3. Standardize SEX Column ---
    # Fill NaN values with 'U' for Unknown.
    df['SEX'].fillna('U', inplace=True)
    # Ensure consistency (e.g., if there were other values like 'Female', they could be mapped here).
    df['SEX'] = df['SEX'].replace({'F': 'F', 'M': 'M'}).fillna('U')
    # Filter to only known values, just in case of dirty data
    df = df[df['SEX'].isin(['F', 'M', 'U'])]

    # --- 4. Handle Missing VAX_MANU ---
    df['VAX_MANU'].fillna('UNKNOWN', inplace=True)

    print("\n--- Final Missing Value Counts (Post-Cleaning) ---")
    print(df[['SYMPTOM_TEXT', 'AGE_YRS', 'SEX', 'VAX_MANU']].isnull().sum())

    # --- 5. Select Relevant Columns for the main project ---
    relevant_columns = [
        'VAERS_ID', 'AGE_YRS', 'SEX', 'SYMPTOM_TEXT', 'DIED', 'DATEDIED',
        'L_THREAT', 'ER_VISIT', 'HOSPITAL', 'HOSPDAYS', 'X_STAY',
        'DISABLE', 'RECOVD', 'VAX_DATE', 'ONSET_DATE', 'NUMDAYS',
        'VAX_MANU', 'VAX_LOT', 'VAX_DOSE_SERIES', 'VAX_ROUTE', 'VAX_SITE',
        'SYMPTOM1', 'SYMPTOM2', 'SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5'
    ]
    
    # Ensure all selected columns exist in the dataframe
    existing_columns = [col for col in relevant_columns if col in df.columns]
    df_cleaned = df[existing_columns]

    print(f"\nFinal dataset shape with selected columns: {df_cleaned.shape}")

    # --- Save the cleaned data ---
    df_cleaned.to_csv(output_filepath, index=False)
    print(f"\nPre-cleaning complete. Cleaned data saved to '{output_filepath}'")

    return df_cleaned

if __name__ == '__main__':
    # The master file generated by the previous script
    INPUT_FILE = 'covid_vaers_master.csv'
    # The new, cleaned file that will be the input for our LangGraph pipeline
    OUTPUT_FILE = 'covid_vaers_cleaned.csv'
    
    clean_vaers_data(INPUT_FILE, OUTPUT_FILE)
